{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Passive Network Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network operators look at different types of network traffic data to understand properties of their networks. Some network data can be collected directly from network devices (e.g., routers, switches) while they are forwarding live traffic.  Collecting this data does not affect network behavior and is therefore called \"passive\" (as opposed to \"active\" measurements).\n",
    "\n",
    "In this assignment, you will analyze two types of passive network measurement data---traffic volumes and BGP routes.\n",
    "\n",
    "This notebook has several parts. Each part contains sections marked with TODO that you need to complete. \n",
    "\n",
    "**You should work with a partner on this assignment. Put your names and netIDs in the cell below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Names:**\n",
    "\n",
    "**NetIds:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Traffic Measurement with IPFIX\n",
    "\n",
    "Routers in most networks collect traffic measurements using the [IPFIX protocol](https://en.wikipedia.org/wiki/IP_Flow_Information_Export). [NetFlow](https://en.wikipedia.org/wiki/NetFlow), a proprietary form of IPFIX defined by Cisco, is well-known in the networks community because Cisco supplies routers for many large networks.\n",
    "\n",
    "In this part of the assignment, you'll analyze a trace of NetFlow records captured from a router that connects the Princeton campus network to the Internet. The assignment will ask you to perform similar kinds of analysis that a network operator would perform -- asking questions about the most popular endpoints for traffic on the Princeton campus, the most popular web applications, and so forth. (As you can imagine, when we start to think about security, the ability to analyze these baselines will come in handy!)\n",
    "\n",
    "The flow records are in the file 'netflow.csv' in the `assignment4` folder.  To simplify the analysis, we have ensured that the IP addresses of the Princeton campus network start with 128.112 and have their 16 lower bits anonymized to protect the privacy of users on the campus network (i.e., all of us!). To further simplify your task, we have parsed these records into CSV (comma-separated variable) format, with the names of the fields listed in the first row of the file. (In a real network, routers export IPFIX records as binary files.)\n",
    "\n",
    "### Measurement of Interdomain Routing with BGP Routing Tables\n",
    "\n",
    "To help network operators understand the state of Internet routing, many routers have the ability to \"dump\" BGP routing tables periodically into a static file. These routing tables contain information about each IP prefix, all BGP routes that the router learns for each prefix, and the \"best\" BGP route that the router ultimately selects. Analyzing the BGP routing tables can provide information about where traffic to different IP prefixes is destined.\n",
    "\n",
    "In this assignment, we have provided you a routing table dump from a project called RouteViews (http://www.routeviews.org/). You can visit that site to learn more about the routing tables that they collect. `telnet route-views2.routeviews.org` will also give you a command-line prompt at a real BGP router at the routeviews project if you want to play around with a live routing table view.  http://routeviews.org/bgpdata/ has periodic binary routing table dumps and update logs from participating routers. Again, for this assignment, we have parsed the binary routing table dumps into a format that is easier to analyze directly. The data is located in the `bgp_rib.csv` file in the `assignment4` directory.\n",
    "\n",
    "### Functional data analysis with map() and reduce()\n",
    "\n",
    "Several of the data analysis steps in this assignment use a \"MapReduce\" programming model. MapReduce originated in functional programming languages and involves using two functions (called `map()` and `reduce()`...surprise!) to apply functions to iterable data (like linked-lists, arrays, etc.). \n",
    "\n",
    "##### map()\n",
    "\n",
    "A general `map()` function has two arguments: another function (which itself takes one argument) and an iterable object. `map()` then applies (maps) the argument function to every item in the iterable object. See the documentation of Python's built-in `map()`function for more details: https://docs.python.org/2/library/functions.html#map. The following toy example uses `map()` to add 3 to every element of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "some_numbers = [1,2,3]\n",
    "three_more = map(lambda x: x+3, some_numbers)\n",
    "print three_more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map()` is often used with anonymous function (the `lambda` in the above example), but can be used just as easily with normal functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add3(i):\n",
    "    return i+3\n",
    " \n",
    "some_numbers = [1,2,3]\n",
    "three_more = map(add3, some_numbers)\n",
    "print three_more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that real implementations of `map()` allow the mapped function to take more than one argument or include more information in a closure, but this won't be necessary for this assignment.\n",
    "\n",
    "##### reduce()\n",
    "\n",
    "A general `reduce()` function takes another function (which itself takes *two* values), an iterable object, and an optional initializer value.  The argument function is applied to the first two elements in the iterable object (or the first element and the initializer value) to get a return value. The function is then applied to this return value and the next item in the iterable object. This continues through the iterable object until only a single return value remains. This allows `reduce()` to compute summaries over all data in the iterable object. See the documentation of Python's built-in `reduce()` function for more details: https://docs.python.org/2/library/functions.html#reduce. The following example uses `reduce()` to count the number of 4s in a list of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_4s(count, i):\n",
    "    # The order of the arguments matters. \n",
    "    #     The first argument is the accumulated value\n",
    "    #     The secod argument is next value from the iterable\n",
    "    if i == 4:\n",
    "        return count + 1\n",
    "    else:\n",
    "        return count\n",
    "\n",
    "some_numbers = [1,4,0,1,4]\n",
    "num_fours = reduce(count_4s, some_numbers, 0) # 0 is the initializer value \n",
    "print num_fours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, real implementations of `reduce()` allow the reduction function to take more than two arguments or include more information in a closure, but this won't be necessary for this assignment.\n",
    "\n",
    "MapReduce programming is popular because it allows analysis tasks on large data sets to be easily parallelized (https://en.wikipedia.org/wiki/MapReduce).  Although there are many open-source and proprietary MapReduce-style data processing libraries (typically with different ways of expressing iterable datasets and distributing tasks over many computers), they all involve `map()` and `reduce()` functions like you will use in this assignment.  If you are interested in learning more about functional programming for data analysis, you should take COS 326."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: IPFIX Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse IPFIX Data\n",
    "The `netflow.csv` file contains pre-processed netflow data from a Princeton campus network border router. The data is \"unsampled,\" i.e. it compiles flow statistics for every packet that traverses any interface on the border router.  We used the `nfdump` tool to process the raw NetFlow data that the router collected. Each row of the `netflow.csv` file, except for the header on top, logs the following information for a flow:\n",
    "\n",
    "```\n",
    "Date first seen, Time first seen (m:s), Date last seen, Time last seen (m:s), Duration (s), Protocol, \n",
    "Src IP addr, Src port, Dst IP addr, Dst port, Packets, Bytes, Flags, Input interface, Output interface\t\t\n",
    "\n",
    "```\n",
    "\n",
    "To analyze this data, we first need to read it into a python data structure.  The following code uses the built-in `csv` library to read `netflow.csv` into a list of dictionaries.  The `csv` library documentation is here if you are interested: https://docs.python.org/2/library/csv.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('netflow.csv', 'r') as netflow_file:\n",
    "    netflow_reader = csv.DictReader(netflow_file)\n",
    "    netflow_data = list(netflow_reader)\n",
    "    \n",
    "print \"Number of flow records: {}\".format(len(netflow_data))\n",
    "print\n",
    "print \"Sample flow record: {}\".format(netflow_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze IPFIX Data\n",
    "\n",
    "The following sections each focus on answering a specific question using the netflow data you have prepared. These questions are both of interest to real network operators and might reveal some surprising facts about how we (as a Princton community) use the Internet.  \n",
    "\n",
    "#### What are the most popular IP addresses accessed by users of the Princeton network?\n",
    "\n",
    "In order to answer this question, we have to decide how to measure IP address popularity. Total traffic volume across all flows seems like a reasonable option, but so does total number of flows to an IP address regardless of volume.  Network operaters actually use both metrics (among others), which we will do here as well.  \n",
    "\n",
    "*Step 1: Determine popular IP addresses by number of flows*\n",
    "\n",
    "Complete the following code to produce a python dictionary `ips_by_flows` with counts of the total number of flows to each external (not 128.112.\\*.\\*) IP address in `netflow_data`.  The keys of the dict should be IP addresses and the values should be integer flow counts.\n",
    "\n",
    "First complete the `count_by_flows()` function, which should take an existing dict of the form described above and update it appropriately from `current_flow`.  If you are confused about datatypes, use print statements to inspect variables. \n",
    "\n",
    "You may want to create an additional helper function to test if an IP address starts with 128.112. Helpful string methods are documented here: https://docs.python.org/2/library/stdtypes.html#string-methods.\n",
    "\n",
    "You will then need to use the `reduce()` function to build a dictionary result.  As a hint, the initializer argument to `reduce()` should be `defaultdict(lambda: 0)`. The [defaultdict()](https://docs.python.org/2/library/collections.html#collections.defaultdict)  function creates a dictionary with default values that are the output of the argument function (in this case, just 0). This allows you to increment the value of a particular key without first checking to see if the key is already in the dictionary (if you used `{}` to create the dict instead of `defaultdict()`, this would raise a KeyError).\n",
    "\n",
    "The provided code will print and plot the most popular IPs.  The `check_ips_by_flows()` function will compare the md5 hash of the top 15 most popular IPs your answer against the md5 hash of the correct answer. This will print a message letting you know whether you are correct or need to keep debugging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from plotting import plot_flows\n",
    "from testing import check_ips_by_flows\n",
    "\n",
    "# TODO: complete count_by_flows function\n",
    "def count_by_flows(counts, current_flow):\n",
    "    # counts is the current dict result\n",
    "    # current_flow being processed\n",
    "    pass\n",
    "      \n",
    "\n",
    "# TODO: use reduce() function to apply count_by_flows to netflow_data and assign the result to ips_by_flows\n",
    "\n",
    "\n",
    "# print the top 5 IP addresses by number of flows \n",
    "sorted_ips_by_flows = sorted(ips_by_flows.items(), reverse=True, key=lambda x: x[1])\n",
    "print \"Most popular IP addresses by number of flows: {}\\n\".format(sorted_ips_by_flows[0:5])\n",
    "\n",
    "# check the results\n",
    "check_ips_by_flows(sorted_ips_by_flows[0:15])\n",
    "\n",
    "# plot the results\n",
    "plot_flows(sorted_ips_by_flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Determine popular IP addresses by total volume*\n",
    "\n",
    "Complete the following code to produce a dict `ips_by_volume` with counts of the total number of bytes to each external (non-Princeton) IP address.  The keys of the dict should be IP addresses and the values should be integer byte counts. Remember that the values in `netflow_data` are strings. You will need to convert them to ints or floats to do arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from plotting import plot_volumes\n",
    "from testing import check_ips_by_volume\n",
    "\n",
    "# TODO: complete count_by_volume function\n",
    "def count_by_volume(counts, current_flow):\n",
    "    # counts is the current dict result\n",
    "    # current_flow being processed\n",
    "    pass\n",
    "\n",
    "        \n",
    "# TODO: use reduce() function to apply count_by_volume to netflow_data and assign the result to ips_by_volume\n",
    "\n",
    "\n",
    "# print the top 5 IP addresses by volume\n",
    "sorted_ips_by_volume = sorted(ips_by_volume.items(), reverse=True, key=lambda x: x[1])\n",
    "print \"Most popular IP addresses by volume: {}\\n\".format(sorted_ips_by_volume[0:5])\n",
    "\n",
    "# check the results\n",
    "check_ips_by_volume(sorted_ips_by_volume[0:15])\n",
    "\n",
    "# plot the results\n",
    "plot_volumes(sorted_ips_by_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the most popular applications (by protocol) for Princeton network users?\n",
    "\n",
    "What application protocols do you think are the most common on the Princeton network?  Web traffic (HTTP & SSL)? Secure remote connection (SSH)? Email (SMTP, IMAP, POP3)?  In practice, a network operator may want to identify popular applications  to make provisioning plans or change network configurations to treat traffic from different applications differently (e.g., to route traffic on different links). This could prevent high-volume applications, (e.g. video streaming) from interrupting the performance of critical low-volume applications.  \n",
    "\n",
    "You can answer these questions by finding the most popular ports of traffic flows in the netflow data. Many application protocols use well-known fixed ports for their traffic.  For example, HTTP traffic happens on port 80, SSL traffic on port 443, SSH traffic on port 22, SMTP on port 25. \n",
    "\n",
    "Again we will use both number of flows and total traffic volume as metrics for port \"popularity\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code to create `ports_by_flows` and `ports_by_volume` dicts from the netflow data.  Use the same strategy as you did above to create `ips_by_flows` and `ips_by_volume`. \n",
    "\n",
    "Include all destination ports and source ports **lower than 1024** (ports lower than 1024 are \"well-known\" and easily mapped to applications). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from plotting import plot_ports\n",
    "from testing import check_ports_by_flows, check_ports_by_volume\n",
    "\n",
    "# TODO: create ports_by_flows and ports_by_volume dicts from netflow_data\n",
    "\n",
    "\n",
    "# Print the most popular ports and check the results\n",
    "sorted_ports_by_flows = sorted(ports_by_flows.items(), reverse=True, key=lambda x: x[1])\n",
    "sorted_ports_by_volume = sorted(ports_by_volume.items(), reverse=True, key=lambda x: x[1])\n",
    "print \"Most popular ports by number of flows: {}\".format(sorted_ports_by_flows[0:5])\n",
    "print \"Most popular ports by volume: {}\\n\".format(sorted_ports_by_volume[0:5])\n",
    "check_ports_by_flows(sorted_ports_by_flows[0:15])\n",
    "check_ports_by_volume(sorted_ports_by_volume[0:15])\n",
    "\n",
    "# plot the results \n",
    "plot_ports(sorted_ports_by_flows, sorted_ports_by_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Answer the following questions about the results of the above analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. \n",
    "What are the 5 most popular external (non-Princeton) IP addresses by number of flows and by traffic volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A1.\n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. \n",
    "Use the \"whois\" command from your Vagrant terminal to learn what you can about these IP addresses (e.g. `whois 169.54.233.126`).  Choose 2 addresses from your answer to Q1 and write up what you learned, as well as why you think they were among the most popular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2. \n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. \n",
    "What are the 5 most popular ports by number of flows and by traffic volume? What applications are associated them? There is a wikipedia page of fixed ports here: https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers. You can also search online to find fixed port/application mappings.  Are you suprised by which applications are the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A3.\n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. \n",
    "Why do you think that telnet (port 23) composes so much of the traffic through Princeton's network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A4. \n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. \n",
    "The provided NetFlow data was captured over a 5 minute period from approximately 6:05am to 6:10am. How much do you think the capture time affected the resulting most popular applications?  What changes would you expect to see if the data had been captured during a different 5 minute window (of your choice)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A5.\n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Analyze BGP Routing Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point in the assignment, we have looked at top traffic flows at the level of IP addresses and ports, but a network operator might also be interested in exploring which other networks (i.e., autonomous systems) are responsible for sending or receiving traffic to the network. From our previous lectures on peering and Internet business relationships, it should be clear why an operator might care about knowing which ASes are sending traffic its way! This information may also be useful for exploring various kinds of network attacks (e.g., sources of denial of service attacks), which we will explore in the next assignment.\n",
    "\n",
    "The RouteViews project allows network operators to obtain real-time information about the global routing system from the perspectives of several different autonomous systems around the Internet. RouteViews servers act as software BGP routers, obtaining their BGP routing information via BGP sessions, just like any other router would learn BGP routes. The main difference between the RouteViews servers and other BGP-speaking routers is that the RouteViews servers do not forward any real Internet traffic.\n",
    "\n",
    "RouteViews periodically logs BGP routing tables (sometimes called a Routing Information Base, or a \"RIB\") in a binary format called MRT. We collected data from one such server and used the `bgpdump` tool to parse the data into a more parsable output format. The entries in the BGP RIB table look like the ones shown below: \n",
    "```\n",
    "TIME: 03/07/16 02:00:00\n",
    "TYPE: TABLE_DUMP_V2/IPV4_UNICAST\n",
    "PREFIX: 0.0.0.0/0\n",
    "SEQUENCE: 0\n",
    "FROM: 185.44.116.1 AS47872\n",
    "ORIGINATED: 03/06/16 20:27:05\n",
    "ORIGIN: IGP\n",
    "ASPATH: 47872 3356\n",
    "NEXT_HOP: 185.44.116.1\n",
    "COMMUNITY: 3356:2 3356:514 3356:2087 47872:1 47872:3356\n",
    "\n",
    "TIME: 03/07/16 02:00:00\n",
    "TYPE: TABLE_DUMP_V2/IPV4_UNICAST\n",
    "PREFIX: 0.0.0.0/0\n",
    "SEQUENCE: 0\n",
    "FROM: 80.241.176.31 AS20771\n",
    "ORIGINATED: 03/04/16 10:21:21\n",
    "ORIGIN: IGP\n",
    "ASPATH: 20771 1299\n",
    "NEXT_HOP: 80.241.176.31\n",
    "```\n",
    "\n",
    "BGP RIBs might have multiple entries for an IP prefix. \n",
    "\n",
    "For this assignment, we considered only a single entry for an IP prefix. We translated this data into the `bgp_rib.csv` file. Each contains the following fields:\n",
    "```\n",
    "TIME, ORIGIN, FROM, SEQUENCE, ASPATH, PREFIX, NEXT_HOP\n",
    "```\n",
    "\n",
    "The following code imports the `bgp_rib.csv` file into a list of dicts (like we did for `netflow_data` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('bgp_rib.csv', 'r') as bgp_file:\n",
    "    bgp_reader = csv.DictReader(bgp_file,delimiter=\";\")\n",
    "    bgp_data = list(bgp_reader)\n",
    "    \n",
    "print \"Number of BGP RIBs: {}\".format(len(bgp_data))\n",
    "print\n",
    "print \"Sample BGP RIB: {}\".format(bgp_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the longest route (by number of unique ASes) in the BGP RouteViews data?\n",
    "\n",
    "To answer this question, you will need to sort `bgp_data` by the number of **unique** AS numbers in the \"ASPATH\" field.  \n",
    "\n",
    "Complete the code below to find the longest ASPATH and assign it to the `longest_aspath` variable.  You can use Python's built-in `sorted()` function (https://docs.python.org/2/library/functions.html#sorted) or another method of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing import check_longest_aspath\n",
    "\n",
    "# TODO: Find the longest (by number of *unique* AS numbers) ASPATH and assign it to the 'longest_aspath' variable\n",
    "\n",
    "\n",
    "# print and check the longest ASPATH\n",
    "print \"The longest ASPATH is: {}\\n\".format(longest_aspath)\n",
    "check_longest_aspath(longest_aspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6.\n",
    "If you search online for \"AS number lookup\" you will find several AS search services. Look up the ASes in this longest route to find their countries of origin. List these countries in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A6. \n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. \n",
    "Why might such long BGP routes be a concern for network operators? Give at least 2 reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A7.\n",
    "*TODO: Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "**Remember to \"Save and Checkpoint\" (from the \"File\" menu above) before you leave the notebook or close your tab.**\n",
    "\n",
    "Submit this file (Assignment4_Notebook.ipynb) on CS Dropbox here: https://dropbox.cs.princeton.edu/COS461_S2017/Assignment_4_-_Passive_Network_Measurement. Submit only once for both partners. Remember to put your names and netids in the marked location at the top of this file. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
